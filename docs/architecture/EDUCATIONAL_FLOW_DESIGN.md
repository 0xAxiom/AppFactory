# Educational Flow Design: From Zero to World-Class Agents

**Date**: 2026-01-17
**Author**: Claude Opus 4.5
**Status**: Learning System Specification

---

## Overview

This document designs a progressive learning system that takes users from zero knowledge of AI agents to the ability to build world-class, production-grade agent systems. Each stage explains concepts in plain language, references Rig explicitly, and ties back to the pipeline structure.

---

## Design Principles

1. **Assume Zero Knowledge**: Every concept is explained from first principles
2. **Progressive Complexity**: Each stage builds on the previous
3. **Concrete Examples**: Abstract concepts are grounded in runnable code
4. **Rig as Reference**: All concepts tie back to Rig's implementation
5. **No Hand-Waving**: Every term is precisely defined
6. **Production Focus**: Examples work in production, not just tutorials

---

## Learning Stages

### Stage 0: What is an Agent? (Mental Model)

**Goal**: Establish a clear mental model of what an agent is and why agents exist.

#### 0.1 The Problem with Static Programs

A traditional program:
- Receives input
- Executes predetermined logic
- Returns output

```
Input → Fixed Logic → Output
```

This works for known problems but fails when:
- The problem requires judgment
- The solution path isn't predetermined
- Context matters and changes

#### 0.2 What Makes Something an "Agent"

An **agent** is a system that:
1. **Perceives** its environment (receives inputs)
2. **Reasons** about what to do (uses intelligence)
3. **Acts** on the environment (produces outputs that change things)
4. **Adapts** based on feedback (learns from results)

**Key Distinction**: An agent doesn't just process data—it makes decisions.

#### 0.3 LLM Agents Specifically

An **LLM agent** uses a Large Language Model as its reasoning engine:

```
Perception → LLM Reasoning → Action → Feedback Loop
```

**Why LLMs?**
- Natural language understanding
- Broad world knowledge
- Reasoning capabilities
- Tool use instruction following

#### 0.4 Rig's Definition

In Rig, an agent is precisely defined:

```rust
// From: references/rig/rig/rig-core/src/agent/completion.rs
pub struct Agent<M> {
    pub name: Option<String>,           // Identity
    pub description: Option<String>,    // Purpose
    pub model: Arc<M>,                  // Reasoning engine (LLM)
    pub preamble: Option<String>,       // Behavior instructions
    pub static_context: Vec<Document>,  // Background knowledge
    pub tool_server_handle: ToolServerHandle, // Available actions
}
```

**Plain Language**: An agent is an LLM + instructions + knowledge + actions.

#### 0.5 When to Use Agents vs. When Not To

**Use an Agent When:**
- The task requires judgment
- The solution path isn't predetermined
- Natural language is the interface
- Multiple tools might be needed

**Don't Use an Agent When:**
- The logic is deterministic
- Performance is critical (sub-100ms)
- The problem is well-defined with known solutions
- Cost is a primary concern

---

### Stage 1: Single-Agent Reasoning Loop

**Goal**: Understand how a single agent reasons and acts.

#### 1.1 The Basic Loop

Every agent follows this loop:

```
┌─────────────┐
│   Prompt    │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│   Reason    │ ◄── LLM processes prompt + context
└──────┬──────┘
       │
       ▼
┌─────────────┐
│   Respond   │ ◄── Generate text or tool call
└──────┬──────┘
       │
       ▼
┌─────────────┐
│   Done?     │
└──────┬──────┘
       │
   ┌───┴───┐
   │       │
   ▼       ▼
  Yes      No ───► Back to Reason
```

#### 1.2 Rig's Implementation

```rust
// Simplified from: references/rig/rig/rig-core/src/agent/prompt_request/mod.rs
impl<M: CompletionModel> PromptRequest<'_, Standard, M, ()> {
    pub async fn await(self) -> Result<String, PromptError> {
        // 1. Build completion request with context
        let request = self.agent.completion(self.prompt, self.history).await?;

        // 2. Send to LLM
        let response = request.send().await?;

        // 3. Handle tool calls if present
        if let Some(tool_calls) = response.tool_calls {
            for tool_call in tool_calls {
                let result = self.agent.tools.call(tool_call.name, tool_call.args).await?;
                // Continue loop...
            }
        }

        // 4. Return final response
        Ok(response.content)
    }
}
```

#### 1.3 TypeScript Equivalent (Generated by Pipeline)

```typescript
// Generated: outputs/<agent>/src/execution/loop.ts
async function runAgent(agent: Agent, prompt: string): Promise<string> {
  let messages = [{ role: 'user', content: prompt }];

  while (true) {
    // 1. Build request with context
    const request = {
      model: agent.model,
      messages,
      systemPrompt: agent.preamble,
      tools: agent.tools.map(t => t.definition()),
    };

    // 2. Send to LLM
    const response = await llm.complete(request);

    // 3. Handle tool calls
    if (response.toolCalls?.length > 0) {
      for (const call of response.toolCalls) {
        const tool = agent.tools.find(t => t.name === call.name);
        const result = await tool.call(call.arguments);
        messages.push({ role: 'tool', content: result });
      }
      continue;  // Loop back to reason
    }

    // 4. Return final response
    return response.content;
  }
}
```

#### 1.4 Key Insight: The Loop is the Agent

An agent isn't the LLM—it's the **loop** that uses the LLM. The loop:
- Manages conversation history
- Coordinates tool execution
- Decides when to stop

---

### Stage 2: Tools + Actions

**Goal**: Understand how agents interact with the world through tools.

#### 2.1 Why Tools?

LLMs can only:
- Read text input
- Write text output

To do anything else (call APIs, read files, execute code), they need **tools**.

**Tool**: A function the agent can request to execute.

#### 2.2 The Tool Contract

Every tool has:
1. **Name**: Unique identifier
2. **Description**: What it does (for LLM understanding)
3. **Parameters**: What input it accepts (JSON Schema)
4. **Output**: What it returns

#### 2.3 Rig's Tool Trait

```rust
// From: references/rig/rig/rig-core/src/tool/mod.rs
pub trait Tool: Sized + Send + Sync {
    const NAME: &'static str;
    type Error: std::error::Error + Send + Sync + 'static;
    type Args: for<'a> Deserialize<'a> + Send + Sync;
    type Output: Serialize;

    fn definition(&self, prompt: String) -> impl Future<Output = ToolDefinition>;
    fn call(&self, args: Self::Args) -> impl Future<Output = Result<Self::Output, Self::Error>>;
}
```

**Key Features**:
- **Typed args/output**: No runtime type errors
- **Typed errors**: Explicit failure modes
- **Async**: Tools can do I/O
- **Definition method**: Tool describes itself

#### 2.4 TypeScript Equivalent

```typescript
// Generated: outputs/<agent>/src/types/tool.ts
interface Tool<TArgs, TOutput> {
  readonly name: string;
  definition(): ToolDefinition;
  call(args: TArgs): Promise<TOutput>;
}

interface ToolDefinition {
  name: string;
  description: string;
  parameters: JSONSchema;
}
```

#### 2.5 Example: Calculator Tool

**Rig (Rust)**:
```rust
impl Tool for Adder {
    const NAME: &'static str = "add";
    type Args = OperationArgs;
    type Output = i32;
    type Error = MathError;

    async fn definition(&self, _prompt: String) -> ToolDefinition {
        ToolDefinition {
            name: "add".to_string(),
            description: "Add two numbers together".to_string(),
            parameters: json!({
                "type": "object",
                "properties": {
                    "x": { "type": "number" },
                    "y": { "type": "number" }
                },
                "required": ["x", "y"]
            }),
        }
    }

    async fn call(&self, args: Self::Args) -> Result<Self::Output, Self::Error> {
        Ok(args.x + args.y)
    }
}
```

**TypeScript (Pipeline Generated)**:
```typescript
const AddTool: Tool<{ x: number; y: number }, number> = {
  name: 'add',
  definition() {
    return {
      name: 'add',
      description: 'Add two numbers together',
      parameters: {
        type: 'object',
        properties: {
          x: { type: 'number' },
          y: { type: 'number' },
        },
        required: ['x', 'y'],
      },
    };
  },
  async call(args) {
    return args.x + args.y;
  },
};
```

#### 2.6 Tool Execution Flow

```
User: "What's 2 + 3?"
      │
      ▼
Agent Reasons: "I need to use the add tool"
      │
      ▼
Agent Requests: { tool: "add", args: { x: 2, y: 3 } }
      │
      ▼
Runtime Executes: AddTool.call({ x: 2, y: 3 }) → 5
      │
      ▼
Agent Receives: "Tool result: 5"
      │
      ▼
Agent Responds: "2 + 3 = 5"
```

---

### Stage 3: Memory + Persistence

**Goal**: Understand how agents maintain state across interactions.

#### 3.1 The Memory Problem

By default, LLMs are stateless. Each call is independent:

```
Call 1: "My name is Alice" → "Nice to meet you, Alice!"
Call 2: "What's my name?"  → "I don't know your name."
```

**Memory** solves this by persisting information across calls.

#### 3.2 Types of Memory

| Type | Scope | Example | Implementation |
|------|-------|---------|----------------|
| **Conversation** | Single session | Chat history | Array of messages |
| **Short-term** | Recent interactions | Last N messages | Sliding window |
| **Long-term** | Persistent facts | User preferences | Database/Vector store |
| **Working** | Current task | Intermediate results | Local state |

#### 3.3 Rig's Approach: External State

Rig does **not** have a built-in memory abstraction. Instead:

1. **Chat history** is passed explicitly
2. **Long-term memory** is via vector stores (RAG)
3. **Working memory** is managed by the application

```rust
// Chat with history
let response = agent.chat("What's my name?", chat_history).await?;

// RAG for long-term context
let agent = client.agent("gpt-4")
    .dynamic_context(5, vector_index)  // Retrieve top 5 relevant docs
    .build();
```

#### 3.4 TypeScript Implementation

```typescript
// Conversation memory (explicit)
class ConversationMemory {
  private messages: Message[] = [];

  add(role: 'user' | 'assistant', content: string) {
    this.messages.push({ role, content });
  }

  getHistory(): Message[] {
    return [...this.messages];
  }

  getRecent(n: number): Message[] {
    return this.messages.slice(-n);
  }
}

// Long-term memory (vector store)
class LongTermMemory {
  constructor(private vectorStore: VectorStore) {}

  async remember(text: string, metadata: object) {
    const embedding = await embed(text);
    await this.vectorStore.insert(embedding, text, metadata);
  }

  async recall(query: string, topK: number = 5): Promise<string[]> {
    const embedding = await embed(query);
    return this.vectorStore.search(embedding, topK);
  }
}
```

#### 3.5 Key Insight: Memory is Application Logic

Rig's philosophy: Memory is **not** the framework's job. The application decides:
- What to remember
- How long to keep it
- When to retrieve it

This is more flexible than baked-in memory systems.

---

### Stage 4: Environment Modeling

**Goal**: Understand how agents perceive and affect their environment.

#### 4.1 What is an Environment?

The **environment** is everything the agent can:
- **Perceive**: Read, query, observe
- **Affect**: Write, execute, modify

#### 4.2 Environment Boundaries

```
┌─────────────────────────────────────────────┐
│               ENVIRONMENT                   │
│                                             │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐    │
│  │  APIs   │  │  Files  │  │   DBs   │    │
│  └────▲────┘  └────▲────┘  └────▲────┘    │
│       │            │            │          │
│       └────────────┼────────────┘          │
│                    │                        │
│              ┌─────┴─────┐                 │
│              │   TOOLS   │                 │
│              └─────▲─────┘                 │
│                    │                        │
│              ┌─────┴─────┐                 │
│              │   AGENT   │                 │
│              └───────────┘                 │
│                                             │
└─────────────────────────────────────────────┘
```

#### 4.3 Read-Only vs. Read-Write Tools

**Read-Only Tools**:
- Fetch data from APIs
- Query databases
- Read files
- Safe to call repeatedly

**Read-Write Tools**:
- Send emails
- Write to databases
- Execute commands
- May have side effects

**Best Practice**: Clearly mark which tools modify state.

#### 4.4 Environment Constraints

Agents should have explicit boundaries:

```typescript
interface EnvironmentConstraints {
  allowedDomains: string[];      // Which APIs can be called
  maxFileSize: number;           // File operation limits
  maxExecutionTime: number;      // Timeout
  disallowedOperations: string[]; // Blocked actions
}
```

#### 4.5 Rig's Safety Model

Rig doesn't enforce environment constraints—that's the application's job. However, the pipeline adds:

```json
// agent.json
{
  "safety": {
    "maxIterations": 10,
    "disallowedActions": [
      "Never execute arbitrary code",
      "Never access files outside workspace"
    ]
  }
}
```

---

### Stage 5: Multi-Agent Coordination

**Goal**: Understand how multiple agents work together.

#### 5.1 Why Multiple Agents?

Single agents hit limits:
- Context window constraints
- Specialized knowledge needs
- Task complexity

**Solution**: Divide work among specialized agents.

#### 5.2 Coordination Patterns

| Pattern | Description | Use Case |
|---------|-------------|----------|
| **Sequential** | A → B → C | Pipelines |
| **Parallel** | A, B, C simultaneously | Independent subtasks |
| **Hierarchical** | Manager delegates to workers | Complex projects |
| **Peer-to-Peer** | Agents communicate directly | Debates, reviews |

#### 5.3 Rig's Approach: Agents as Tools

In Rig, agents can be tools for other agents:

```rust
// From: references/rig/rig/rig-core/examples/agent_with_agent_tool.rs
let calculator_agent = client.agent("gpt-4")
    .preamble("You are a calculator...")
    .tool(Adder)
    .tool(Subtract)
    .build();

// Calculator agent IS A TOOL for the orchestrator
let orchestrator = client.agent("gpt-4")
    .preamble("You are a helpful assistant...")
    .tool(calculator_agent)  // Agent as tool!
    .build();
```

#### 5.4 Orchestration Example

```typescript
// Orchestrator pattern in TypeScript
async function orchestrate(task: string): Promise<string> {
  // 1. Break down task
  const subtasks = await plannerAgent.prompt(`Break down: ${task}`);

  // 2. Assign to specialists
  const results = await Promise.all(
    subtasks.map(async (subtask) => {
      if (subtask.type === 'research') {
        return researcherAgent.prompt(subtask.description);
      } else if (subtask.type === 'code') {
        return coderAgent.prompt(subtask.description);
      } else {
        return generalistAgent.prompt(subtask.description);
      }
    })
  );

  // 3. Synthesize results
  return synthesizerAgent.prompt(`Combine: ${results.join('\n')}`);
}
```

#### 5.5 Key Insight: Agents are Composable

The power of Rig's model: **every agent is a tool**. This enables:
- Recursive delegation
- Specialization
- Scaling complexity

---

### Stage 6: Agents + dApps

**Goal**: Understand how agents integrate with blockchain applications.

#### 6.1 What is a dApp?

A **decentralized application (dApp)** combines:
- Smart contracts (on-chain logic)
- Off-chain compute (backend/agents)
- User interface (frontend)

#### 6.2 Where Agents Fit in dApps

```
┌─────────────────────────────────────────────────────────┐
│                       dApp                               │
│                                                         │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐ │
│  │   Frontend  │◄──►│   Agents    │◄──►│  Contracts  │ │
│  │   (React)   │    │   (Rig)     │    │  (Solidity) │ │
│  └─────────────┘    └─────────────┘    └─────────────┘ │
│         │                 │                   │         │
│         │                 │                   │         │
│         ▼                 ▼                   ▼         │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐ │
│  │   User      │    │   APIs/     │    │  Blockchain │ │
│  │   Wallet    │    │   Indexers  │    │   State     │ │
│  └─────────────┘    └─────────────┘    └─────────────┘ │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

#### 6.3 Agent Responsibilities in dApps

| Responsibility | Example | Why Agent? |
|----------------|---------|------------|
| **Transaction Building** | Construct swap txs | Complex logic |
| **Strategy Execution** | DCA, rebalancing | Ongoing decisions |
| **Data Interpretation** | Explain tx history | Natural language |
| **Risk Assessment** | Warn about scams | Judgment required |
| **Cross-Chain Coordination** | Bridge operations | Multi-step |

#### 6.4 Rig-Onchain-Kit

Rig has a companion library for blockchain:

```rust
// From: rig-onchain-kit (separate repo)
use rig_onchain_kit::{SolanaTools, EvmTools};

let defi_agent = client.agent("gpt-4")
    .preamble("You are a DeFi assistant...")
    .tool(SolanaTools::transfer())
    .tool(SolanaTools::swap())
    .tool(EvmTools::call_contract())
    .build();
```

#### 6.5 When NOT to Use Agents in dApps

**Do NOT use agents for:**
- Custodial operations (holding user funds)
- High-frequency trading (latency matters)
- Simple CRUD operations (deterministic)
- Fully on-chain logic (contracts handle it)

**DO use agents for:**
- User intent interpretation
- Complex strategy execution
- Cross-system coordination
- Explanation and assistance

#### 6.6 Decision Gate: Does This dApp Need Agents?

Before integrating agents, ask:

```
1. Does the dApp require autonomous reasoning?     YES/NO
2. Does the dApp involve multi-step decisions?    YES/NO
3. Does the dApp need natural language interface? YES/NO
4. Does the dApp coordinate multiple systems?     YES/NO
5. Is latency tolerance > 1 second?               YES/NO

If 3+ YES → Consider agents
If 2 or fewer YES → Probably don't need agents
```

---

## Summary: The Learning Path

```
Stage 0: What is an Agent?
    │
    │ "An agent is an LLM + instructions + knowledge + actions"
    │
    ▼
Stage 1: Reasoning Loop
    │
    │ "The loop is the agent, not the LLM"
    │
    ▼
Stage 2: Tools
    │
    │ "Tools are how agents affect the world"
    │
    ▼
Stage 3: Memory
    │
    │ "Memory is application logic, not framework magic"
    │
    ▼
Stage 4: Environment
    │
    │ "Agents perceive and affect bounded environments"
    │
    ▼
Stage 5: Multi-Agent
    │
    │ "Agents are composable—every agent can be a tool"
    │
    ▼
Stage 6: Agents + dApps
    │
    │ "Agents handle judgment; contracts handle rules"
    │
    ▼
WORLD-CLASS AGENT BUILDER
```

---

## Appendix: Rig Reference Locations

| Concept | Rig Source File |
|---------|-----------------|
| Agent struct | `rig/rig-core/src/agent/completion.rs` |
| Agent builder | `rig/rig-core/src/agent/builder.rs` |
| Tool trait | `rig/rig-core/src/tool/mod.rs` |
| Pipeline | `rig/rig-core/src/pipeline/mod.rs` |
| Vector stores | `rig/rig-core/src/vector_store/` |
| Providers | `rig/rig-core/src/providers/` |
| Examples | `rig/rig-core/examples/` |

---

**End of Educational Flow Design**
